q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(M1:C5)
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
if (model_type == "elastic net"){
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)
estimated_diff = estimated_diff[length(estimated_diff)] # Take only last prediction at point of convergence
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
# Find quantiles for confidence intervals
ci_ll = quantile(boot_estimated_diffs %>% as.matrix(), 0.025)
ci_ul = quantile(boot_estimated_diffs %>% as.matrix(), 0.975)
row = bind_cols(
scenario = scenario,
dataset = dataset,
metal = metal,
point_estimate = estimated_diff,
CI_lower = ci_ll,
CI_upper = ci_ul
)
metals = bind_rows(metals, row)
}
datasets = bind_rows(datasets, metals)
}
estimates = bind_rows(estimates, datasets)
}
model_performance = cbind(performance(estimates), model_type)
return(model_performance)
}
# Testing models
linear_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 10, model_type = "linear")
linear_df
elastic_net_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 10, model_type = "elastic net")
all_models_df = rbind(linear_df, elastic_net_df)
# Test graphics function
perform_graphics(model_name = "elastic net", all_models_df)
# Testing model performance
linear_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 100, model_type = "linear")
elastic_net_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 100, model_type = "elastic net")
all_models_df = rbind(linear_df, elastic_net_df)
# Test graphics function
perform_graphics(model_name = "elastic net", all_models_df)
all_models_df
# Function to fit models
model_fit_fnct = function(model_type, data){
if (model_type %in% c("linear")){
fit = lm(Y ~ .,
data = data)
}
else if (model_type %in% c("elastic net")){
x_data = data %>%
dplyr::select(-Y) %>%
as.matrix()
y_data = data %>%
dplyr::select(Y) %>%
as.matrix()
# Force covariates into model (specify covariates not to drop; 0 for vars to keep)
p_fac = rep(1, dim(x_data)[2])
p_fac[11:15] = 0 # Keep confounders in model
# Vector of values identifying what fold each observation is in for 10-fold cross-validation
fold_id = sample(x = 1:10, size = length(y_data), replace = TRUE)
# Fit model to training data with cross-validation
# Alpha = 1 by default
cv_fit = cv.glmnet(
x = x_data,
y = y_data,
family = "gaussian",
maxit = 5000,
penalty.factor = p_fac,
foldid = fold_id
)
# Need to hard code cross-validation over range of alpha values
for (i in seq(0, 1, by = 0.1)){
cv_temp = cv.glmnet(
x = x_data,
y = y_data,
family = "gaussian",
maxit = 5000,
penalty.factor = p_fac,
foldid = fold_id,
alpha = i
)
if(min(cv_temp$cvm) < min(cv_fit$cvm))
{cv_fit = cv_temp}
}
# Optimal beta coefficients
selected_beta_coefs = array(t(as.matrix(coef(cv_fit,
s = cv_fit$lambda.min))))
# Final trained model for prediction
# Returns elastic net model with coefficients across grid of values for regularization parameter lambda
fit = glmnet(
x = x_data,
y = y_data,
family = "gaussian",
init = selected_beta_coefs,
iter = 0
)
}
else if (model_type %in% c("MARS")){
train_data = data %>%
as.matrix()
# Specify confounders to force into the model
covars = c("C1", "C2", "C3", "C4", "C5")
# Implement 5-fold CV using caret package
myControl = trainControl(
method = "cv",
number = 5,
summaryFunction = defaultSummary
)
# Set hyperparameter tuning grid, may want to consider different values
hyper_grid = expand.grid(
degree = c(1,2), # Limit to up to second-order polynomials
nprune = seq(5, 50, length.out = 10) %>% floor()
)
# Fit model
fit = train(
Y ~ .,
data = train_data,
method = "earth",
linpreds = covars, # Enter covariates linearly
thresh = 0, # Include a predictor even if it has very little predictive power
penalty = -1, # Do not discard any terms in backwards pass
trControl = myControl,
tuneGrid = hyper_grid
)
}
return(fit)
}
model_fnct = function(scenarios_count, datasets_count, metals_count, boot_count, model_type){
estimates = data.frame()
for (scenario in 1:scenarios_count){
datasets = data.frame()
filtered_datasets = dataset_filter(scenario)
for (dataset in 1:datasets_count){
data = filtered_datasets[[dataset]] %>% as.data.frame() %>% dplyr::select(M1:Y)
model_fits = model_fit_fnct(model_type, data)
boot_fits = boot_fnct(model_type, data, boot_count)
metals = data.frame()
for (metal in 1:metals_count){
if (model_type == "linear"){
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(M1:C5)
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(M1:C5)
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
else if (model_type == "elastic net"){
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)
estimated_diff = estimated_diff[length(estimated_diff)] # Take only last prediction at point of convergence
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
else if (model_type == "MARS"){
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(-Y) %>% as.matrix()
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(-Y) %>% as.matrix()
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
# Find quantiles for confidence intervals
ci_ll = quantile(boot_estimated_diffs %>% as.matrix(), 0.025)
ci_ul = quantile(boot_estimated_diffs %>% as.matrix(), 0.975)
row = bind_cols(
scenario = scenario,
dataset = dataset,
metal = metal,
point_estimate = estimated_diff,
CI_lower = ci_ll,
CI_upper = ci_ul
)
metals = bind_rows(metals, row)
}
datasets = bind_rows(datasets, metals)
}
estimates = bind_rows(estimates, datasets)
}
model_performance = cbind(performance(estimates), model_type)
return(model_performance)
}
# Function to bootstrap N times on a given model
boot_fnct = function(model_type, bootstrap_data, boot_count){
set.seed(2132)
boot = bootstrap_data %>%
dplyr::select(M1:Y) %>%
bootstraps(times = boot_count) %>%
rowwise() %>%
mutate(data_sample = (list(analysis(splits)))) %>%
dplyr::select(id, data_sample) %>%
ungroup() %>%
mutate(models = map(data_sample, model_type = model_type, model_fit_fnct)) %>%
dplyr::select(-data_sample)
return(boot)
}
# Function to estimate causal effect using fitted model
predict_diff_fnct = function(model_type, fitted_model, q1, q2){
if (model_type %in% c("linear","elastic net", "MARS")){
predicted = predict(fitted_model, q2) - predict(fitted_model, q1)
return(predicted)
}
}
# predict_diff_fnct = function(fitted_model){
#
#   effect = ifelse(
#     model == "BART",
#     # For BART, SE medians from MC draws; is there a better way?
#     quantile(predict(fitted_model, q2), 0.5) - quantile(predict(fitted_model, q1), 0.5),
#     ifelse(
#       model == "GAM_MGCV",
#       predict(fitted_model, q2 %>% as.data.frame()) - predict(fitted_model, q1 %>% as.data.frame()),
#       ifelse(
#         model == "SuperLearner",
#         predict(fitted_model, q2, type = "response")$pred - predict(superlearner_fit, q1, type = "response")$pred,
#         ifelse(
#           model == "QuantileGComp" | model == "AMCGComp",
#           predict(fitted_model$fit, q2) - predict(fitted_model$fit, q1),
#           predict(fitted_model, q2) - predict(fitted_model, q1)
#         )
#       )
#     )
#   )
#
#   return(effect)
#
# }
# Function to estimate causal effects using fitted model on bootstraps
predict_diff_boots = function(model_type, boots, q1, q2){
bstar = NULL
n = dim(boots)[1];
for (mod in 1:n) {
if (model_type == "elastic net"){
quant1 = predict(boots[[2]][[mod]], q1)
quant1 = quant1[length(quant1)] # Pull for smallest lambda
quant2 = predict(boots[[2]][[mod]], q2)
quant2 = quant2[length(quant2)] # Pull for smallest lambda
diff = tibble(diff = quant2 - quant1)[[1]]
}
else if (model_type == "BART"){
# Use medians; is there a better method?
quant1 = quantile(predict(boots[[2]][[mod]], q1), 0.5)
quant2 = quantile(predict(boots[[2]][[mod]], q2), 0.5)
diff = tibble(diff = quant2 - quant1)[[1]]
}
else {
diff = tibble(diff = predict_diff_fnct(
model_type,
fitted_model = boots[[2]][[mod]],
q1,
q2)[[1]]
)
}
bstar = rbind(bstar, diff)
} # Next draw
return(bstar)
}
# Function to fit models
model_fit_fnct = function(model_type, data){
if (model_type %in% c("linear")){
fit = lm(Y ~ .,
data = data)
}
else if (model_type %in% c("elastic net")){
x_data = data %>%
dplyr::select(-Y) %>%
as.matrix()
y_data = data %>%
dplyr::select(Y) %>%
as.matrix()
# Force covariates into model (specify covariates not to drop; 0 for vars to keep)
p_fac = rep(1, dim(x_data)[2])
p_fac[11:15] = 0 # Keep confounders in model
# Vector of values identifying what fold each observation is in for 10-fold cross-validation
fold_id = sample(x = 1:10, size = length(y_data), replace = TRUE)
# Fit model to training data with cross-validation
# Alpha = 1 by default
cv_fit = cv.glmnet(
x = x_data,
y = y_data,
family = "gaussian",
maxit = 5000,
penalty.factor = p_fac,
foldid = fold_id
)
# Need to hard code cross-validation over range of alpha values
for (i in seq(0, 1, by = 0.1)){
cv_temp = cv.glmnet(
x = x_data,
y = y_data,
family = "gaussian",
maxit = 5000,
penalty.factor = p_fac,
foldid = fold_id,
alpha = i
)
if(min(cv_temp$cvm) < min(cv_fit$cvm))
{cv_fit = cv_temp}
}
# Optimal beta coefficients
selected_beta_coefs = array(t(as.matrix(coef(cv_fit,
s = cv_fit$lambda.min))))
# Final trained model for prediction
# Returns elastic net model with coefficients across grid of values for regularization parameter lambda
fit = glmnet(
x = x_data,
y = y_data,
family = "gaussian",
init = selected_beta_coefs,
iter = 0
)
}
else if (model_type %in% c("MARS")){
train_data = data %>%
as.matrix()
# Specify confounders to force into the model
covars = c("C1", "C2", "C3", "C4", "C5")
# Implement 5-fold CV using caret package
myControl = trainControl(
method = "cv",
number = 5,
summaryFunction = defaultSummary
)
# Set hyperparameter tuning grid, may want to consider different values
hyper_grid = expand.grid(
degree = c(1,2), # Limit to up to second-order polynomials
nprune = seq(5, 50, length.out = 10) %>% floor()
)
# Fit model
fit = train(
Y ~ .,
data = train_data,
method = "earth",
linpreds = covars, # Enter covariates linearly
thresh = 0, # Include a predictor even if it has very little predictive power
penalty = -1, # Do not discard any terms in backwards pass
trControl = myControl,
tuneGrid = hyper_grid
)
}
return(fit)
}
model_fnct = function(scenarios_count, datasets_count, metals_count, boot_count, model_type){
estimates = data.frame()
for (scenario in 1:scenarios_count){
datasets = data.frame()
filtered_datasets = dataset_filter(scenario)
for (dataset in 1:datasets_count){
data = filtered_datasets[[dataset]] %>% as.data.frame() %>% dplyr::select(M1:Y)
model_fits = model_fit_fnct(model_type, data)
boot_fits = boot_fnct(model_type, data, boot_count)
metals = data.frame()
for (metal in 1:metals_count){
if (model_type == "linear"){
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(M1:C5)
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(M1:C5)
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
else if (model_type == "elastic net"){
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)
estimated_diff = estimated_diff[length(estimated_diff)] # Take only last prediction at point of convergence
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
else if (model_type == "MARS"){
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(-Y) %>% as.matrix()
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(-Y) %>% as.matrix()
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
# For each bootstrap, predict effect estimate
boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
}
# Find quantiles for confidence intervals
ci_ll = quantile(boot_estimated_diffs %>% as.matrix(), 0.025)
ci_ul = quantile(boot_estimated_diffs %>% as.matrix(), 0.975)
row = bind_cols(
scenario = scenario,
dataset = dataset,
metal = metal,
point_estimate = estimated_diff,
CI_lower = ci_ll,
CI_upper = ci_ul
)
metals = bind_rows(metals, row)
}
datasets = bind_rows(datasets, metals)
}
estimates = bind_rows(estimates, datasets)
}
model_performance = cbind(performance(estimates), model_type)
return(model_performance)
}
mars_df = model_fnct(scenarios_count = 2, datasets_count = 2, metals_count = 2, boot_count = 2, model_type = "MARS")
mars_df
scenario = 1
dataset = 1
metal = 2
estimates = data.frame()
datasets = data.frame()
filtered_datasets = dataset_filter(scenario)
data = filtered_datasets[[dataset]] %>% as.data.frame() %>% dplyr::select(M1:Y)
data
model_type = "MARS"
model_fits = model_fit_fnct(model_type, data)
model_fits
boot_fits = boot_fnct(model_type, data, boot_count)
boot_count = 2
boot_fits = boot_fnct(model_type, data, boot_count)
boot_fits
metals = data.frame()
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(-Y) %>% as.matrix()
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(-Y) %>% as.matrix()
q1
q2
# Apply fitted model to original data to estimate causal effect
estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
estimated_diff
predict(fit, q2)
fit
model_fits
predict(model_fits, q2)
predict(model_fits, q1)
q2
q1
model_fits
predict(model_fit, q2)
predict(model_fits, q2)
predict(model_fits, q1)
# Set Q1 and Q2 for estimand
q1 = metal_IQR_table(scenario = scenario, metal = metal)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
q2 = metal_IQR_table(scenario = scenario, metal = metal)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
predict(model_fits, q2)
predict(model_fits, q1)
model_fits
model_fits$finalModel
set.seed(2132)
mars_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 5, model_type = "MARS")
mars_df
all_models_df = rbind(linear_df, elastic_net_df, mars_df)
# Test graphics function
perform_graphics(model_name = "MARS", all_models_df)
# Function for performance metrics
performance_metrics = function(estimates, scenario, metal){
true_effect = true_effects[scenario, metal + 1]
estimates = estimates %>%
dplyr::select(-dataset) %>%
filter(scenario == {{scenario}} & metal == {{metal}}) %>%
mutate(
true_effect = as.numeric(true_effect)
) %>%
mutate(
bias = abs(true_effect - point_estimate),
relative_bias = bias / true_effect,
standard_error = (true_effect - point_estimate)^2,
includes = if_else(CI_lower <= true_effect & CI_upper >= true_effect,
1,
0),
CI_length = CI_upper - CI_lower,
sig_effect = case_when(
CI_lower > 0 & CI_upper > 0 ~ 1,
CI_lower < 0 & CI_upper < 0 ~ 1,
CI_lower < 0 & CI_upper > 0 ~ 0
)
)
estimates_grouped = estimates %>%
group_by(scenario, metal) %>%
mutate(
RMSE = sqrt(mean(standard_error)),
coverage = mean(includes),
TDR = dplyr::case_when(
metal %in% c(1, 5) ~ mean(sig_effect, na.rm = TRUE)
),
FDR = dplyr::case_when(
!(metal %in% c(1, 5)) ~ mean(sig_effect, na.rm = TRUE)
)
)
row = estimates_grouped %>%
dplyr::select(scenario, metal, RMSE, coverage, TDR, FDR) %>%
head(1)
return(row)
}
# Testing model performance
linear_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 100, model_type = "linear")
# Testing model performance
linear_df = model_fnct(scenarios_count = 5, datasets_count = M, metals_count = 5, boot_count = 5, model_type = "linear")
linear_df
# Testing model performance
linear_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 100, model_type = "linear")
mars_df = model_fnct(scenarios_count = 10, datasets_count = M, metals_count = 10, boot_count = 100, model_type = "MARS")
savehistory("~/Desktop/History.Rhistory")
