---
title: "Data Simulation: New Scenario [Pressure Testing]"
author: "Zachary Katz (UNI: zak2132)"
date: "2023-03-04"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r}
# Load packages
library(tidyverse)
library(MASS)
library(corrplot)
library(faux)
library(glmnet)
library(rsample)
library(caret)
library(patchwork)

# To avoid annoying message
options(dplyr.summarise.inform = FALSE)
```

# Generate data

```{r}
# Data simulation function

data_simulation = function(scenario, N = 1000) {
  
  # Create scenario to pressure test simple models (e.g. linear, elastic net)
  # Similar to prior Scenario 7 (complex exposures [nonlinear/interaction] + complex confounding)
  # Decrease signal from metals in functional form
  # Increase signal from confounders
  # Add negative interaction for metals in functional form
  
  if (scenario == "Pressure Test"){
    
    # Simulate 15 normally distributed variables: 10 exposures and 5 confounders
    correlated_vars = rnorm_multi(
      n = N,
      mu = rep(x = 1, 15),
      sd = rep(x = 0.2, 15),
      r = 0.25,
      varnames = c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8", "M9", "M10", "C1", "C2", "C3", "C4", "C5"),
      empirical = FALSE
    )
    
    # Confound M1 and M2 with more complexity than before
    M1 = rnorm(
          N, 
          mean = sin(0.2*correlated_vars[, 11] + 0.2*correlated_vars[, 12] + 0.2*correlated_vars[, 13] +
                    0.2*correlated_vars[, 14] + 0.2*correlated_vars[, 15]) + 0.8*correlated_vars[, 1],
          sd = 0.2
        )
  
    M2 = rnorm(
          N, 
          mean = sin(0.2*correlated_vars[, 11] + 0.2*correlated_vars[, 12] + 0.2*correlated_vars[, 13] +
                    0.2*correlated_vars[, 14] + 0.2*correlated_vars[, 15]) + 0.8*correlated_vars[, 2],
          sd = 0.2
        )  
    
    sim_df = data.frame(M1, M2, correlated_vars[, 3:15])
    colnames(sim_df[, 1:10]) = paste("exposure_", 1:10, sep = "") 
    colnames(sim_df[, 11:15]) = paste("confounder_", 1:5, sep = "")
    
    # Simulate nonlinear effect with interactions from two exposures (M1, M5) and nonlinear effect with interactions from five confounders (C1, C2, C3, C4, C5)
    # M1 is confounded with C1-5, M5 is not
    # M2 is correlated with C1-5, but has no direct effect on outcome (spurious association)
    hfunY = function(z) h_fun_Y(z, ind1 = 1, ind2 = 5, ind3 = 11, ind4 = 12, ind5 = 13, ind6 = 14, ind7 = 15) 
    h_fun_Y = function(z, ind1, ind2, ind3, ind4, ind5, ind6, ind7) {
      
        0.1*(z[ind1])^2 + 0.1*(z[ind2])^2 - 0.3*(z[ind1])*(z[ind2]) + # Complex exposure effect (nonlinear/interaction)
        0.6*(z[ind3])^2 + 0.6*(z[ind4])^2 + 0.6*(z[ind5])^2 + 0.6*z[ind6] + 0.6*z[ind7] + # Quadratic confounding effect from C1-3
        0.5*(z[ind6])*(z[ind7]) # Interactive confounding effect from C4, C5
    }
    
    sim_df$hY = apply(sim_df, 1, hfunY) 
    
    # Add noise
    epsY = rnorm(N, mean = 1, sd = 0.2)
    sim_df$Y = with(sim_df, hY + epsY)
    
    # Remove unused columns
    sim_df = sim_df %>% 
      dplyr::select(-hY)
    
    # Return simulated data
    return(sim_df)
    
  }
  
}

# Check correlations
data = data_simulation(scenario = "Pressure Test", N = 1000)
corr = cor(data)
corrplot(corr, type = "upper")
```

```{r}
# Function for functional forms

functional_forms = function(scenario, covars){

  if (scenario == "Pressure Test"){
    
    a = 0.1*(covars[1])^2 + 0.1*(covars[5])^2 - 0.3*(covars[1]*covars[5]) + 0.6*(covars[11])^2 + 0.6*(covars[12])^2 + 0.6*(covars[13])^2 + 0.6*covars[14] + 0.6*covars[15] + 0.5*(covars[14])*(covars[15])
      
    }

  return(a)   
}
```

```{r}
# Simulate M data sets of N observations for each scenario
set.seed(2132)
M = 400 # number of data sets per scenario
N = 1000 # number of observations per data set

simulated_data = list()

for (scenario in "Pressure Test"){
  
  simulated_data_loop = lapply(1:M, function(i) data_simulation(scenario = scenario, N = N))
  
  for (data_frame in 1:M){
    
    simulated_data_loop[[data_frame]]$scenario = scenario
    
  }
  
  simulated_data = append(simulated_data, simulated_data_loop)
  
}
```

# Estimands and true effects

```{r}
# First estimand of interest: effect of interquartile range change in exposure levels

quantiles = data.frame()

# For each scenario, simulate 1000 datasets with 1000 observations

set.seed(2132)

for (i in "Pressure Test"){
  
  for (j in 1:1000){
    
    sim_data = data_simulation(scenario = i, N = 1000)
    q1 = apply(sim_data, 2, function(x) quantile(x, 0.25))
    med = apply(sim_data, 2, median)
    q2 = apply(sim_data, 2, function(x) quantile(x, 0.75))
    quantiles = bind_rows(
      quantiles,
      bind_cols(scenario = i, quantile = c(0.25, 0.50, 0.75),
      bind_rows(q1, med, q2)
      )
    )
    
  }
  
}

# For each scenario, average across datasets for each quantile of a given metal

# Function for table
metal_IQR_table = function(scenario, metal){
  
  # Average across datasets of each quantile for given metal in given scenario
  m.25 = quantiles %>% 
          filter(quantile == 0.25 & scenario == {{scenario}}) %>% 
          dplyr::select(c(metal + 2)) %>% 
          t() %>% 
          mean()
    
  m.75 = quantiles %>% 
          filter(quantile == 0.75 & scenario == {{scenario}}) %>% 
          dplyr::select(c(metal + 2)) %>% 
          t() %>% 
          mean()
  
  filtered = filter(quantiles, quantile == 0.5 & scenario == {{scenario}})
  
  filtered = filtered %>% 
    dplyr::select(M1:Y)
  
  # For interquartile range change
  # Create tables with all vars at median except for given exposure to obtain potential outcomes (counterfactuals)
  q1.m = apply(filtered, 2, mean)
  q1.m[[c(metal)]] = m.25
  q2.m = q1.m
  q2.m[[c(metal)]] = m.75
  
  table = rbind(q1.m, q2.m) %>% as.data.frame()
  
  return(table)
  
}

# Function for causal effect (difference in potential outcomes)
metal_IQR_effect = function(scenario, metal){
  
  # Obtain metal IQR table
  table = metal_IQR_table(scenario, metal)
  
  # Calculate true effect
  true_effect = functional_forms(scenario, table[2, ]) - functional_forms(scenario, table[1, ])
  
  return(true_effect[[1]])
  
}
```

```{r}
# Calculate true effects
true_effects = data.frame()

for (scenario_i in "Pressure Test"){
  
  for (metal_j in 1:10){
    
    effect = metal_IQR_effect(scenario_i, metal_j)
    true_effects = bind_rows(
      true_effects,
      bind_cols(scenario = scenario_i,
                metal = metal_j,
                effect = effect)
    )
    
  }
  
}

true_effects = true_effects %>% 
  pivot_wider(
    names_from = metal,
    values_from = effect
  )
```

```{r}
# Repeat but for aggregate mixture profiles

# Function for table
metal_IQR_mix_table = function(scenario){
  
  # Average across datasets of each quantile for given metal in given scenario
  m.25 = quantiles %>% 
    filter(quantile == 0.25 & scenario == {{scenario}}) %>% 
    dplyr::select(M1:M10)
    
  m.75 = quantiles %>% 
    filter(quantile == 0.75 & scenario == {{scenario}}) %>% 
    dplyr::select(M1:M10)
  
  c.50 = quantiles %>% 
    filter(quantile == 0.50 & scenario == {{scenario}}) %>% 
    dplyr::select(C1:C5)
  
  q.1.means = apply(m.25, 2, mean)
  q.2.means = apply(m.75, 2, mean)
  c.means = apply(c.50, 2, mean)
  
  table = rbind(q.1.means, q.2.means) %>% as.data.frame()
  confound = rbind(c.means, c.means)
  table = cbind(table, confound)
  
  return(table)
  
}

# Function for causal effect with aggregate mixture profile
metal_IQR_mix_effect = function(scenario){
  
  # Obtain metal IQR table
  table = metal_IQR_mix_table(scenario)
  
  # Calculate true effect
  true_effect = functional_forms(scenario, table[2, ]) - functional_forms(scenario, table[1, ])
  
  return(true_effect[[1]])
  
}

# Calculate true effects
true_effects_mixture = data.frame()

for (scenario in "Pressure Test"){
    
    effect = metal_IQR_mix_effect(scenario)
    true_effects_mixture = bind_rows(
      true_effects_mixture,
      bind_cols(scenario = scenario,
                effect = effect)
    )
  
}
```

```{r}
boot_fnct = function(model_type, bootstrap_data, boot_count){
  
  set.seed(2132)
  
  boot = bootstrap_data %>% 
    dplyr::select(M1:Y) %>%
    bootstraps(times = boot_count) %>% 
    rowwise() %>% 
    mutate(data_sample = (list(analysis(splits)))) %>% 
    dplyr::select(id, data_sample) %>% 
    ungroup() %>%
    mutate(models = map(data_sample, model_type = model_type, model_fit_fnct)) %>% 
    dplyr::select(-data_sample)
  
  return(boot)
  
}

# Function to estimate causal effect using fitted model
predict_diff_fnct = function(model_type, fitted_model, q1, q2){
  
  if (model_type %in% c("linear","elastic net", "MARS", "GAM", "Random Forest", "GAM2", "Causal Forest")){
    
    predicted = predict(fitted_model, q2) - predict(fitted_model, q1)

  }
  
  else if (model_type %in% c("BART")){
    
    # For BART, SE medians from MC draws; is there a better way?
    predicted = quantile(predict(fitted_model, q2), 0.5) - quantile(predict(fitted_model, q1), 0.5)
    
  }
  
  else if (model_type %in% c("SuperLearner")){
    
    predicted = predict(fitted_model, q2, type = "response")$pred - predict(fitted_model, q1, type = "response")$pred
    
  }
  
  else if (model_type %in% c("Quantile G-Computation", "AMC G-Computation")){
    
    exposures = c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8", "M9", "M10")
    
    predicted = predict(object = fitted_model, expnms = exposures, newdata = q2) - predict(object = fitted_model, expnms = exposures, newdata = q1)
    
  }
  
  else if (model_type %in% c("BKMR1")){
    
    predicted = 
      mean(
        SamplePred(fitted_model,
                     Znew = q2[,variable.names(fitted_model$Z)],
                     Xnew = as.matrix(q2[,variable.names(fitted_model$X)]))
        - 
          SamplePred(fitted_model,
                   Znew = q1[,variable.names(fitted_model$Z)],
                   Xnew = as.matrix(q1[,variable.names(fitted_model$X)]))
                   )
    
  }
  
  else if (model_type %in% c("BKMR2")){
    
    predicted = 
      mean(
        SamplePred(fitted_model,
                     Znew = q2[,variable.names(fitted_model$Z)])
        - 
          SamplePred(fitted_model,
                   Znew = q1[,variable.names(fitted_model$Z)])
                   )
    
  }

  return(predicted)
  
}

# Function to estimate causal effects using fitted model on bootstraps
predict_diff_boots = function(model_type, boots, q1, q2){
  
  bstar = NULL 
  n = dim(boots)[1];
  
  for (mod in 1:n) {
    
    if (model_type == "elastic net"){
      
      quant1 = predict(boots[[2]][[mod]], q1)
      quant1 = quant1[length(quant1)] # Pull for smallest lambda
      quant2 = predict(boots[[2]][[mod]], q2)
      quant2 = quant2[length(quant2)] # Pull for smallest lambda
      diff = tibble(diff = quant2 - quant1)[[1]]
      
    }
    
    else if (model_type == "BART"){
      
      # Use medians; is there a better method?
      quant1 = quantile(predict(boots[[2]][[mod]], q1), 0.5)
      quant2 = quantile(predict(boots[[2]][[mod]], q2), 0.5)
      diff = tibble(diff = quant2 - quant1)[[1]]
      
    }
    
    else {
      
      diff = tibble(diff = predict_diff_fnct(
        model_type,
        fitted_model = boots[[2]][[mod]],
        q1,
        q2)[[1]]
    )
      
    }
    
    bstar = rbind(bstar, diff)
  } # Next draw
  
  return(bstar)
  
}
```

# Test models

```{r}
# Function to fit models
model_fit_fnct = function(model_type, data){
  
  if (model_type %in% c("linear")){
    
    fit = lm(Y ~ ., 
          data = data)
    
  }
  
  else if (model_type %in% c("elastic net")){
    
    x_data = data %>% 
      dplyr::select(-Y) %>% 
      as.matrix()
    
    y_data = data %>% 
      dplyr::select(Y) %>% 
      as.matrix()
  
    # Force covariates into model (specify covariates not to drop; 0 for vars to keep)
    p_fac = rep(1, dim(x_data)[2])
    p_fac[11:15] = 0 # Keep confounders in model
    
    # Vector of values identifying what fold each observation is in for 10-fold cross-validation
    fold_id = sample(x = 1:10, size = length(y_data), replace = TRUE)
    
    # Fit model to training data with cross-validation
    # Alpha = 1 by default
    cv_fit = cv.glmnet(
      x = x_data,
      y = y_data,
      family = "gaussian",
      maxit = 5000,
      penalty.factor = p_fac,
      foldid = fold_id 
    )
    
    # Need to hard code cross-validation over range of alpha values
    for (i in seq(0, 1, by = 0.1)){
      cv_temp = cv.glmnet(
        x = x_data,
        y = y_data,
        family = "gaussian",
        maxit = 5000,
        penalty.factor = p_fac,
        foldid = fold_id,
        alpha = i
      )
      
      if(min(cv_temp$cvm) < min(cv_fit$cvm)) 
        {cv_fit = cv_temp}
    
  }
  
  # Optimal beta coefficients
  selected_beta_coefs = array(t(as.matrix(coef(cv_fit,
                                         s = cv_fit$lambda.min))))
  
  # Final trained model for prediction
  # Returns elastic net model with coefficients across grid of values for regularization parameter lambda
  fit = glmnet(
    x = x_data,
    y = y_data,
    family = "gaussian",
    init = selected_beta_coefs,
    iter = 0
  )
    
  }
  
  else if (model_type %in% c("MARS")){
    
    train_data = data %>% 
      as.matrix()
  
    # Specify confounders to force into the model
    covars = c("C1", "C2", "C3", "C4", "C5") 
    
    # Implement 5-fold CV using caret package
    myControl = trainControl(
      method = "cv",
      number = 5,
      summaryFunction = defaultSummary
    )
    
    # Set hyperparameter tuning grid, may want to consider different values
    hyper_grid = expand.grid(
      degree = c(1,2), # Limit to up to second-order polynomials
      nprune = seq(5, 50, length.out = 10) %>% floor()
    )
    
    # Fit model
    fit = train(
      Y ~ .,
      data = train_data,
      method = "earth",
      linpreds = covars, # Enter covariates linearly
      thresh = 0, # Include a predictor even if it has very little predictive power
      penalty = -1, # Do not discard any terms in backwards pass
      trControl = myControl,
      tuneGrid = hyper_grid
    )
    
  }
  
  else if (model_type %in% c("GAM")){
    
    x_train = data %>% 
      dplyr::select(M1:C5) %>% 
      as.matrix()
  
    y_train = data %>% 
      dplyr::select(Y) %>% 
      as.matrix() %>% 
      as.numeric()
    
    # Cross-validation for smoothing functions
    ctrl = trainControl(method = "cv", number = 10)
    
    # Grid for hyperparameters
    # select = TRUE/FALSE for variable selection using GCV
    grid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE))
    
    # Fit GAM
    fit = train(
      x = x_train, # By default, GAM adds s() term for predictors having > 10 values, linear for those that do not
      y = y_train,
      method = "gam", # MGCV implementation of GAM
      tuneGrid = grid,
      trControl = ctrl
  )
    
  }
  
  else if (model_type %in% c("BART")){
    
    x_train = data %>%
      dplyr::select(M1:C5) %>%
      as.matrix()

    y_train = data %>%
      dplyr::select(Y) %>%
      as.matrix()

    fit = mc.wbart( # Use mc.wbart for parallel computation (just regular wbart without)
      x.train = x_train,
      y.train = y_train,
      x.test = x_train,
      ntree = 50, # Number of trees in the sum
      nskip = 250, # Number of MCMC iterations to be treated as burn in
      ndpost = 1000, # Number of posterior draws returned
      keepevery = 250,
      seed = 2132,
      mc.cores = 4 # Parallel computing
    )

  }
  
  else if (model_type %in% c("Random Forest")){
    
    train_data = data %>% 
      as.matrix()
  
    ctrl = trainControl(method = "cv") 
    
    rf_grid = expand.grid(
      mtry = 1:10, # of predictors at each split
      splitrule = "variance", # RSS
      min.node.size = 1:6 # Controls size of tree
    )
    
    fit = train(
      Y ~ ., # Assumes no interaction terms?
      data = train_data,
      method = "ranger",
      tuneGrid = rf_grid,
      trControl = ctrl
    )
    
  }
  
  else if (model_type %in% c("GAM2")){
  
  # Fit GAM using MGCV
  fit = mgcv::gam(
    # k = 4 is max polynomial for smoothing basis
    Y ~ ti(M1, k = 4) + ti(M2, k = 4) + ti(M3, k = 4) + ti(M4, k = 4) + ti(M5, k = 4) + ti(M6, k = 4) + ti(M7, k = 4) + ti(M8, k = 4) + ti(M9, k = 4) + ti(M10, k = 4) + 
      # Add two-way interactions for tensor smoothing
      ti(M1, M2, k = 4) + ti(M1, M3, k = 4) + ti(M1, M4, k = 4) + ti(M1, M5, k = 4) + ti(M1, M6, k = 4) + ti(M1, M7, k = 4) + ti(M1, M8, k = 4) + ti(M1, M9, k = 4) + ti(M1, M10, k = 4) + ti(M2, M3, k = 4) + ti(M2, M4, k = 4) + ti(M2, M5, k = 4) + ti(M2, M6, k = 4) + ti(M2, M7, k = 4) + ti(M2, M8, k = 4) + ti(M2, M9, k = 4) + ti(M2, M10, k = 4) + ti(M3, M4, k = 4) + ti(M3, M5, k = 4) + ti(M3, M6, k = 4) + ti(M3, M7, k = 4) + ti(M3, M8, k = 4) + ti(M3, M9, k = 4) + ti(M3, M10, k = 4) + ti(M4, M5, k = 4) + ti(M4, M6, k = 4) + ti(M4, M7, k = 4) + ti(M4, M8, k = 4) + ti(M4, M9, k = 4) + ti(M4, M10, k = 4) + ti(M5, M6, k = 4) + ti(M5, M7, k = 4) + ti(M5, M8, k = 4) + ti(M5, M9, k = 4) + ti(M5, M10, k = 4) + ti(M6, M7, k = 4) + ti(M6, M8, k = 4) + ti(M6, M9, k = 4) + ti(M6, M10, k = 4) + ti(M7, M8, k = 4) + ti(M7, M9, k = 4) + ti(M7, M10, k = 4) + ti(M8, M9, k = 4) + ti(M8, M10, k = 4) + ti(M9, M10, k = 4) + 
      # Add covariates
      C1 + C2 + C3 + C4 + C5,
    data = data,
    method = "REML"
  )
    
  }
  
  else if (model_type %in% c("SuperLearner")){
    
    x_train = data %>% 
      dplyr::select(M1:C5) %>% 
      as.data.frame()
  
    y_train = data %>% 
      dplyr::select(Y) %>% 
      as.matrix() %>% 
      as.numeric()
  
    # Select variety of candidate learners, some parametric, some non-parametric
    SL_library_chosen = c("SL.glmnet", "SL.randomForest", "SL.glm", "SL.ranger", "SL.xgboost", "SL.svm", "SL.earth", "SL.gbm", "SL.ranger")
  
    # Select loss function for meta learner and estimate risk
    # Here, use non-negative least squares loss
    loss_chosen = "method.NNLS"
    
    # Fit WITHOUT cross-validation (try with CV later to improve stability / robustness?)
    fit = SuperLearner(
      Y = y_train,
      X = x_train,
      SL.library = SL_library_chosen,
      family = "gaussian",
      method = loss_chosen,
      verbose = FALSE
    )
    
  }
  
  else if (model_type %in% c("Quantile G-Computation")){
    
    data = data %>% 
      dplyr::select(M1:Y) %>% 
      as.data.frame()
  
    exposures = c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8", "M9", "M10")
    
    # Fit g-computation model with all two-way interactions (including self-interactions, i.e. quadratic terms)
    fit = qgcomp.boot(
      Y ~ . + .^2,
      data = data,
      family = gaussian(),
      expnms = exposures,
      q = 4, # Number of quantiles to create indicators representing exposure vars (can increase if we want)
      B = 200, # Number of bootstrap iterations
      degree = 2, # Polynomial bases for marginal model
      seed = 2132
    )
    
    # https://github.com/alexpkeil1/qgcomp/blob/main/vignettes/qgcomp-vignette.Rmd 
    # Note: Why don't I get weights from the `boot` functions?
# Users often use the `qgcomp.*.boot` functions because the want to marginalize over confounders or fit a non-linear joint exposure function. In both cases, the overall exposure response will no longer correspond to a simple weighted average of model coefficients, so none of the `qgcomp.*.boot` functions will calculate weights. In most use cases, the weights would vary according to which level of joint exposure you're at, so it is not a straightforward proposition to calculate them (and you may not wish to report 4 sets of weights if you use the default `q=4`). If you fit an otherwise linear model, you can get weights from a `qgcomp.*.noboot` which will be very close to the weights you might get from a linear model fit via `qgcomp.*.boot` functions, but be explicit that the weights come from a different model than the inference about joint exposure effects.
    
  }
  
  else if (model_type %in% c("Causal Forest")){
    
    # Causal random forest (`grf`) using regression_forest, which trains a regression forest that can be used to estimate the conditional mean function mu(x) = E[Y | X = x]
    # https://grf-labs.github.io/grf/REFERENCE.html#:~:text=For%20regression%20forests%2C%20the%20prediction,status%20of%20the%20neighbor%20examples.
    # Note: should I use quantile_forest instead?
    
    x_train = data %>% 
      dplyr::select(M1:C5) %>% 
      as.matrix()
  
    y_train = data %>% 
      dplyr::select(Y) %>% 
      as.matrix()
    
    # Fit regression forest model using mostly defaults
    fit = regression_forest(
      X = x_train,
      Y = y_train,
      seed = 2132
      
  )
    
  }
  
  else if (model_type %in% c("AMC G-Computation")){
    
    data = data %>% 
      distinct() # To make it work with bootstrapping (other contrasts issue re: number of levels)
  
    x_train = data %>% 
      dplyr::select(M1:C5)
    
    amc_result = amc(
      data = x_train
    )
    
    output = amc_result$output
    
    oldseed = .Random.seed
    
    output = cbind(data %>% dplyr::select(Y), output)
    
    exposures = c("M1", "M2", "M3", "M4", "M5", "M6", "M7", "M8", "M9", "M10")
    
    # Obtain joint mixture effect using same method as Quantile-based G-Computation
    fit = qgcomp.boot(
      Y ~ . + .^2,
      data = output,
      family = gaussian(),
      expnms = exposures,
      q = 4, # Number of quantiles to create indicators representing exposure vars (can increase if we want)
      B = 200, # Number of bootstrap iterations
      degree = 2, # Polynomial bases for marginal model
      seed = 2132
    )
    
  }
  
  else if (model_type %in% c("BKMR1")){
    
    data = data %>% 
      distinct()
  
    covars = data %>% 
      dplyr::select(C1:C5) %>% 
      as.matrix()
    
    exposures = data %>% 
      dplyr::select(M1:M10) %>% 
      as.matrix()
    
    y_train = data %>% 
      dplyr::select(Y) %>% 
      as.matrix()
    
    # Use knots to improve speed
    knots100 = fields::cover.design(
      exposures,
      nd = 100
    )$design
    
    # Fit BKMR using MCMC
    fit = kmbayes(
      y = y_train,
      Z = exposures,
      X = covars,
      iter = 1000, # Change to 10000; run time was too long
      varsel = TRUE, # Variable selection,
      est.h = TRUE
    )
    
  }
  
  else if (model_type %in% c("BKMR2")){
    
    data = data %>% 
      distinct()
    
    exposures_and_covars = data %>% 
      dplyr::select(M1:C5) %>% 
      as.matrix()
    
    y_train = data %>% 
      dplyr::select(Y) %>% 
      as.matrix()
    
    # Use knots to improve speed
    knots100 = fields::cover.design(
      exposures_and_covars,
      nd = 100
    )$design
    
    # Fit BKMR using MCMC
    fit = kmbayes(
      y = y_train,
      Z = exposures_and_covars,
      iter = 1000, # Change to 10000; run time was too long
      varsel = TRUE, # Variable selection,
      est.h = TRUE
    )
    
  }
  
  return(fit)
  
}
```

```{r}
model_fnct = function(datasets_count, metals_count, boot_count, model_type){
  
  estimates = data.frame()
  
  for (i in "Pressure Test"){
    
    datasets = data.frame()
    
    for (j in 1:datasets_count){
      
      data = simulated_data[[j]] %>% as.data.frame() %>% dplyr::select(M1:Y)
      
      model_fits = model_fit_fnct(model_type, data)
      
      boot_fits = boot_fnct(model_type, data, boot_count)
      
      metals = data.frame()
      
      for (k in 1:metals_count){
        
        if (model_type %in% c("linear", "GAM", "GAM2", "SuperLearner", "Quantile G-Computation", "AMC G-Computation", "BKMR1", "BKMR2")){
          
          # Set Q1 and Q2 for estimand
          q1 = metal_IQR_table(i, k)[1, ] %>% dplyr::select(M1:C5) # Consider reverting back to without curly brackets?
          q2 = metal_IQR_table(i, k)[2, ] %>% dplyr::select(M1:C5) # Consider reverting back to without curly brackets?
          
          # Set Q1 and Q1 for aggregate mixture profile
          q1_mix = metal_IQR_mix_table(i)[1, ] %>% dplyr::select(M1:C5)
          q2_mix = metal_IQR_mix_table(i)[2, ] %>% dplyr::select(M1:C5)
          
          # Apply fitted model to original data to estimate causal effect for individual metals and for mixture profile
          estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
          estimated_diff_mix = predict_diff_fnct(model_type, model_fits, q1_mix, q2_mix)[[1]]
          
          # For each bootstrap, predict effect estimate for individual metals and for mixture profile
          boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
          boot_estimated_diffs_mix = predict_diff_boots(model_type, boot_fits, q1_mix, q2_mix)
          
        }
        
        else if (model_type == "elastic net"){
            
            # Set Q1 and Q2 for estimand
            q1 = metal_IQR_table(i, k)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
            q2 = metal_IQR_table(i, k)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
            
            # Set Q1 and Q1 for aggregate mixture profile
            q1_mix = metal_IQR_mix_table(i)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
            q2_mix = metal_IQR_mix_table(i)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
                
            # Apply fitted model to original data to estimate causal effect
            estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)
            estimated_diff = estimated_diff[length(estimated_diff)] # Take only last prediction at point of convergence
            estimated_diff_mix = predict_diff_fnct(model_type, model_fits, q1_mix, q2_mix)
            estimated_diff_mix = estimated_diff_mix[length(estimated_diff_mix)]
            
            # For each bootstrap, predict effect estimate
            boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
            boot_estimated_diffs_mix = predict_diff_boots(model_type, boot_fits, q1_mix, q2_mix)
            
        }
          
        else if (model_type %in% c("MARS", "Random Forest", "Causal Forest")){
          
          # Set Q1 and Q2 for estimand
          q1 = metal_IQR_table(i, k)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          q2 = metal_IQR_table(i, k)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          
          # Set Q1 and Q1 for aggregate mixture profile
          q1_mix = metal_IQR_mix_table(i)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          q2_mix = metal_IQR_mix_table(i)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          
          # Apply fitted model to original data to estimate causal effect
          estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
          estimated_diff_mix = predict_diff_fnct(model_type, model_fits, q1_mix, q2_mix)[[1]]
            
          # For each bootstrap, predict effect estimate
          boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
          boot_estimated_diffs_mix = predict_diff_boots(model_type, boot_fits, q1_mix, q2_mix)
          
        }
          
        else if (model_type == "BART"){
          
          # Set Q1 and Q2 for estimand
          q1 = metal_IQR_table(i, k)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          q2 = metal_IQR_table(i, k)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          
          # Set Q1 and Q1 for aggregate mixture profile
          q1_mix = metal_IQR_mix_table(i)[1, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          q2_mix = metal_IQR_mix_table(i)[2, ] %>% dplyr::select(M1:C5) %>% as.matrix()
          
          # Apply fitted model to original data to estimate causal effect
          # Using median difference for BART; is there a preferable method, e.g. yhat.train.mean or yhat.test.mean?
          estimated_diff = predict_diff_fnct(model_type, model_fits, q1, q2)[[1]]
          estimated_diff_mix = predict_diff_fnct(model_type, model_fits, q1_mix, q2_mix)[[1]]
          
          # For each bootstrap, predict effect estimate
          boot_estimated_diffs = predict_diff_boots(model_type, boot_fits, q1, q2)
          boot_estimated_diffs_mix = predict_diff_boots(model_type, boot_fits, q1_mix, q2_mix)
          
        }
        
        # Find quantiles for confidence intervals
        ci_ll = quantile(boot_estimated_diffs %>% as.matrix(), 0.025)
        ci_ul = quantile(boot_estimated_diffs %>% as.matrix(), 0.975)
        ci_ll_mix = quantile(boot_estimated_diffs_mix %>% as.matrix(), 0.025)
        ci_ul_mix = quantile(boot_estimated_diffs_mix %>% as.matrix(), 0.975)
        
        # Find variance
        variance_indiv = var(boot_estimated_diffs)
        variance_mix = var(boot_estimated_diffs_mix)
        
        row = bind_cols(
          scenario = i,
          dataset = j,
          metal = k,
          point_estimate = estimated_diff,
          variance = variance_indiv,
          CI_lower = ci_ll,
          CI_upper = ci_ul
        )
        
        metals = bind_rows(metals, row)
  
        }
      
      row_mix = bind_cols(
      scenario = i,
      dataset = j,
      metal = 11, # Must be numeric; consider metal 11 as aggregate mixture
      point_estimate = estimated_diff_mix,
      variance = variance_mix,
      CI_lower = ci_ll_mix,
      CI_upper = ci_ul_mix
    )
    
      metals = bind_rows(metals, row_mix)  
      datasets = bind_rows(datasets, metals)
      
    }
    
    estimates = bind_rows(estimates, datasets)
    
  }
  
  output = cbind(estimates, model_type)
  return(output)
  
}
```

```{r}
# Linear model
set.seed(2132)
t1 = Sys.time()
linear_df = model_fnct(datasets_count = 400, metals_count = 10, boot_count = 100, model_type = "linear")
t2 = Sys.time()
linear_time = t2 - t1
```

```{r}
# Analyze model results
linear_df = linear_df %>% 
  mutate(
    scenario = as.factor(scenario),
    metal = as.factor(metal)
  ) %>% 
  distinct()
```

```{r, cache = TRUE}
model_performance_dataset_level = function(df){
  
  rows = data.frame()
  
  df = df %>% 
    dplyr::select(scenario:model_type)
  
  model_type = df$model_type[1]
  
  for (row_num in 1:nrow(df)){
    
    row = df[row_num, ]
    
    if (as.numeric(row$metal) %in% c(1:10)){
    
      true_effect = true_effects[as.numeric(row$scenario), as.numeric(row$metal) + 1]
    
    }
    
    if (as.numeric(row$metal) %in% c(11)){
    
      true_effect = true_effects_mixture[as.numeric(row$scenario), ][, 2]
    
    }
    
    row_truth = row %>%
      mutate(
        true_effect = as.numeric(true_effect)
      ) %>%
      mutate(
        point_bias = true_effect - point_estimate,
        relative_bias = point_bias / true_effect,
        standard_error = (true_effect - point_estimate)^2,
        includes = if_else(CI_lower <= true_effect & CI_upper >= true_effect,
                           1,
                           0),
        CI_length = CI_upper - CI_lower,
        sig_effect = case_when(
          CI_lower > 0 & CI_upper > 0 ~ 1,
          CI_lower < 0 & CI_upper < 0 ~ 1,
          CI_lower < 0 & CI_upper > 0 ~ 0
        )
      )
    
    rows = rbind(rows, row_truth)
    
  }
  
  return(rows)
  
}

model_performance_scenario_level = function(df){
  
  rows = data.frame()
  
  df = df %>% 
    dplyr::select(scenario:model_type)
  
  model_type = df$model_type[1]
  
  for (row_num in 1:nrow(df)){
    
    row = df[row_num, ]
    
    if (as.numeric(row$metal) %in% c(1:10)){
    
      true_effect = true_effects[as.numeric(row$scenario), as.numeric(row$metal) + 1]
    
    }
    
    if (as.numeric(row$metal) %in% c(11)){
    
      true_effect = true_effects_mixture[as.numeric(row$scenario), ][, 2]
    
    }
    
    row_truth = row %>%
      mutate(
        true_effect = as.numeric(true_effect)
      ) %>%
      mutate(
        point_bias = abs(true_effect - point_estimate),
        relative_bias = point_bias / true_effect,
        standard_error = (true_effect - point_estimate)^2,
        includes = if_else(CI_lower <= true_effect & CI_upper >= true_effect,
                           1,
                           0),
        CI_length = CI_upper - CI_lower,
        sig_effect = case_when(
          CI_lower > 0 & CI_upper > 0 ~ 1,
          CI_lower < 0 & CI_upper < 0 ~ 1,
          CI_lower < 0 & CI_upper > 0 ~ 0
        )
      )
    
    rows = rbind(rows, row_truth)
    
  }
  
  performance_summary = rows %>% 
    group_by(scenario, metal) %>%
    summarize(
        RMSE = sqrt(mean(standard_error)),
        coverage = mean(includes),
        mean_sig_effect = mean(sig_effect)
      ) %>%
    mutate(
      power = dplyr::case_when(
        metal %in% c(1, 5, 11) ~ mean_sig_effect,
        !(metal %in% c(1, 5, 11)) ~ 1 - mean_sig_effect)
    ) %>% 
    dplyr::select(scenario, metal, RMSE, coverage, power)
  
  performance_summary$model_type = model_type
  
  return(performance_summary)
  
}
```

```{r, cache = TRUE, message = FALSE, warning = FALSE}
linear_model_performance_dataset_level_pressure_test = model_performance_dataset_level(linear_df)
linear_model_performance_scenario_level_pressure_test = model_performance_scenario_level(linear_df)
```

```{r}
# Relative bias distributions

# Individual metals
linear_model_performance_dataset_level_pressure_test %>% 
  filter(metal %in% c(1,5)) %>% 
  ggplot(aes(x = model_type, y = relative_bias)) + 
  geom_boxplot() + 
  facet_grid(. ~ scenario) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + 
  labs(title = "Distribution of Relative Bias by Scenario & Model",
       subtitle = "For Exposures in Functional Form (Metals 1 & 5)")

# Mixture
linear_model_performance_dataset_level_pressure_test %>% 
  filter(metal == 11) %>% 
  ggplot(aes(x = model_type, y = relative_bias)) + 
  geom_boxplot() + 
  facet_grid(. ~ scenario) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + 
  labs(title = "Distribution of Relative Bias by Scenario & Model",
       subtitle = "For Full Metal Mixture")
```

```{r}
# Relative bias medians, grouped by metal

# Individual metals
linear_model_performance_dataset_level_pressure_test %>% 
  filter(metal %in% c(1,5)) %>% 
  group_by(scenario, metal, model_type) %>% 
  summarize(
    median_relative_bias = median(relative_bias)
  ) %>% 
  ggplot(aes(x = model_type, y = median_relative_bias)) + 
  geom_point() + 
  facet_grid(metal ~ scenario) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Median Relative Bias by Scenario & Model, Grouped by Metal",
       subtitle = "For Exposures in Functional Form (Metals 1 & 5)")

# Mixture
linear_model_performance_dataset_level_pressure_test %>% 
  filter(metal == 11) %>% 
  group_by(scenario, metal, model_type) %>% 
  summarize(
    median_relative_bias = median(relative_bias)
  ) %>% 
  ggplot(aes(x = model_type, y = median_relative_bias)) + 
  geom_point() + 
  facet_grid(. ~ scenario) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Median Relative Bias by Scenario & Model",
       subtitle = "For Full Metal Mixture")
```